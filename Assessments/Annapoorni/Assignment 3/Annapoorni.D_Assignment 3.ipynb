{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d365b03a",
   "metadata": {},
   "source": [
    "# IMAGE AUGMENTATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2eb458a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.preprocessing.image import load_img\n",
    "import scipy\n",
    "import sklearn\n",
    "import numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b5a52ff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen=ImageDataGenerator(rescale=1./255, zoom_range=0.2,horizontal_flip=True,vertical_flip=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3f125d88",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_datagen=ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3dd963e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4317 images belonging to 5 classes.\n"
     ]
    }
   ],
   "source": [
    "x_train=train_datagen.flow_from_directory(r\"D:\\IBM\\Asssignment\\Flowers-Dataset\\flowers\",target_size=(64,64),class_mode='categorical',batch_size=24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2f99ca99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4317 images belonging to 5 classes.\n"
     ]
    }
   ],
   "source": [
    "x_test=test_datagen.flow_from_directory(r\"D:\\IBM\\Asssignment\\Flowers-Dataset\\flowers\",target_size=(64,64),class_mode='categorical',batch_size=24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ecd8f148",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'daisy': 0, 'dandelion': 1, 'rose': 2, 'sunflower': 3, 'tulip': 4}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.class_indices"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "263fc222",
   "metadata": {},
   "source": [
    "# INITIALIZING CNN AND CREATE MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a92e7167",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense,Convolution2D,MaxPooling2D,Flatten"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89b6cede",
   "metadata": {},
   "source": [
    "# ADD LAYERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f2107efe",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Sequential()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "457a52a9",
   "metadata": {},
   "source": [
    "# INPUT LAYERS (CONVOLUTION ,MAXPOOLING,FLATTEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "76395297",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Convolution2D(32,(3,3),input_shape=(64,64,3),activation='relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3b9af2d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(MaxPooling2D(pool_size=(2,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dd0d68ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2c15a12d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 62, 62, 32)        896       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 31, 31, 32)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 30752)             0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 896\n",
      "Trainable params: 896\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f9497c7",
   "metadata": {},
   "source": [
    "# HIDDEN LAYERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "eb0bd983",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dense(300,activation='relu'))\n",
    "model.add(Dense(150,activation='relu'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7e6ba46",
   "metadata": {},
   "source": [
    "# OUTPUT LAYERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c2bcd83c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dense(5,activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f613e5da",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a00f7587",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "180"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd306589",
   "metadata": {},
   "source": [
    "# TRAIN THE MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a5080cc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "180/180 [==============================] - 37s 199ms/step - loss: 1.4182 - accuracy: 0.4508 - val_loss: 1.0940 - val_accuracy: 0.5543\n",
      "Epoch 2/30\n",
      "180/180 [==============================] - 30s 164ms/step - loss: 1.0564 - accuracy: 0.5879 - val_loss: 1.0189 - val_accuracy: 0.6099\n",
      "Epoch 3/30\n",
      "180/180 [==============================] - 30s 165ms/step - loss: 0.9661 - accuracy: 0.6245 - val_loss: 0.9261 - val_accuracy: 0.6447\n",
      "Epoch 4/30\n",
      "180/180 [==============================] - 31s 173ms/step - loss: 0.9016 - accuracy: 0.6551 - val_loss: 0.8849 - val_accuracy: 0.6634\n",
      "Epoch 5/30\n",
      "180/180 [==============================] - 31s 173ms/step - loss: 0.8399 - accuracy: 0.6718 - val_loss: 0.8241 - val_accuracy: 0.6905\n",
      "Epoch 6/30\n",
      "180/180 [==============================] - 30s 166ms/step - loss: 0.8146 - accuracy: 0.6810 - val_loss: 0.7028 - val_accuracy: 0.7431\n",
      "Epoch 7/30\n",
      "180/180 [==============================] - 31s 174ms/step - loss: 0.7526 - accuracy: 0.7111 - val_loss: 0.6806 - val_accuracy: 0.7422\n",
      "Epoch 8/30\n",
      "180/180 [==============================] - 30s 167ms/step - loss: 0.6991 - accuracy: 0.7329 - val_loss: 0.7204 - val_accuracy: 0.7243\n",
      "Epoch 9/30\n",
      "180/180 [==============================] - 30s 166ms/step - loss: 0.6862 - accuracy: 0.7410 - val_loss: 0.5887 - val_accuracy: 0.7776\n",
      "Epoch 10/30\n",
      "180/180 [==============================] - 29s 163ms/step - loss: 0.6350 - accuracy: 0.7633 - val_loss: 0.5394 - val_accuracy: 0.7985\n",
      "Epoch 11/30\n",
      "180/180 [==============================] - 30s 166ms/step - loss: 0.5977 - accuracy: 0.7730 - val_loss: 0.5316 - val_accuracy: 0.8029\n",
      "Epoch 12/30\n",
      "180/180 [==============================] - 29s 163ms/step - loss: 0.5744 - accuracy: 0.7876 - val_loss: 0.4838 - val_accuracy: 0.8277\n",
      "Epoch 13/30\n",
      "180/180 [==============================] - 30s 166ms/step - loss: 0.5394 - accuracy: 0.8003 - val_loss: 0.4336 - val_accuracy: 0.8429\n",
      "Epoch 14/30\n",
      "180/180 [==============================] - 30s 168ms/step - loss: 0.4978 - accuracy: 0.8101 - val_loss: 0.3904 - val_accuracy: 0.8573\n",
      "Epoch 15/30\n",
      "180/180 [==============================] - 31s 170ms/step - loss: 0.4860 - accuracy: 0.8186 - val_loss: 0.4961 - val_accuracy: 0.8281\n",
      "Epoch 16/30\n",
      "180/180 [==============================] - 30s 167ms/step - loss: 0.4618 - accuracy: 0.8307 - val_loss: 0.4092 - val_accuracy: 0.8506\n",
      "Epoch 17/30\n",
      "180/180 [==============================] - 30s 166ms/step - loss: 0.4404 - accuracy: 0.8374 - val_loss: 0.2971 - val_accuracy: 0.8927\n",
      "Epoch 18/30\n",
      "180/180 [==============================] - 30s 166ms/step - loss: 0.4087 - accuracy: 0.8494 - val_loss: 0.3101 - val_accuracy: 0.8877\n",
      "Epoch 19/30\n",
      "180/180 [==============================] - 32s 176ms/step - loss: 0.3729 - accuracy: 0.8661 - val_loss: 0.3699 - val_accuracy: 0.8680\n",
      "Epoch 20/30\n",
      "180/180 [==============================] - 30s 169ms/step - loss: 0.3612 - accuracy: 0.8677 - val_loss: 0.2578 - val_accuracy: 0.9062\n",
      "Epoch 21/30\n",
      "180/180 [==============================] - 30s 168ms/step - loss: 0.3088 - accuracy: 0.8886 - val_loss: 0.2391 - val_accuracy: 0.9185\n",
      "Epoch 22/30\n",
      "180/180 [==============================] - 31s 170ms/step - loss: 0.3067 - accuracy: 0.8923 - val_loss: 0.2322 - val_accuracy: 0.9143\n",
      "Epoch 23/30\n",
      "180/180 [==============================] - 30s 167ms/step - loss: 0.2610 - accuracy: 0.9041 - val_loss: 0.1934 - val_accuracy: 0.9349\n",
      "Epoch 24/30\n",
      "180/180 [==============================] - 30s 168ms/step - loss: 0.2781 - accuracy: 0.9029 - val_loss: 0.2303 - val_accuracy: 0.9217\n",
      "Epoch 25/30\n",
      "180/180 [==============================] - 31s 174ms/step - loss: 0.2371 - accuracy: 0.9178 - val_loss: 0.1849 - val_accuracy: 0.9423\n",
      "Epoch 26/30\n",
      "180/180 [==============================] - 30s 166ms/step - loss: 0.2382 - accuracy: 0.9180 - val_loss: 0.1674 - val_accuracy: 0.9426\n",
      "Epoch 27/30\n",
      "180/180 [==============================] - 30s 168ms/step - loss: 0.2364 - accuracy: 0.9168 - val_loss: 0.2057 - val_accuracy: 0.9300\n",
      "Epoch 28/30\n",
      "180/180 [==============================] - 30s 167ms/step - loss: 0.2272 - accuracy: 0.9194 - val_loss: 0.1404 - val_accuracy: 0.9521\n",
      "Epoch 29/30\n",
      "180/180 [==============================] - 30s 169ms/step - loss: 0.2120 - accuracy: 0.9298 - val_loss: 0.1993 - val_accuracy: 0.9326\n",
      "Epoch 30/30\n",
      "180/180 [==============================] - 30s 165ms/step - loss: 0.2111 - accuracy: 0.9273 - val_loss: 0.1437 - val_accuracy: 0.9474\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x21389b9bd90>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train,steps_per_epoch=len(x_train), validation_data=x_test, validation_steps=len(x_test), epochs= 30)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a741beb5",
   "metadata": {},
   "source": [
    "# SAVE THE MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "28755a1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('Flowers_classification_model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71dee3b7",
   "metadata": {},
   "source": [
    "# TEST THE MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "143dcf34",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing import image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f8b3f1a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model\n",
    "model=load_model('Flowers_classification_model1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2a7003f9",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'D:\\\\IBM\\\\Asssignment\\\\Flowers-Dataset\\\\flowers\\\\daisy.jpeg'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [29], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m img\u001b[38;5;241m=\u001b[39m\u001b[43mimage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_img\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mD:\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43mIBM\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43mAsssignment\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43mFlowers-Dataset\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43mflowers\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43mdaisy.jpeg\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mtarget_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m64\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m64\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\utils\\image_utils.py:422\u001b[0m, in \u001b[0;36mload_img\u001b[1;34m(path, grayscale, color_mode, target_size, interpolation, keep_aspect_ratio)\u001b[0m\n\u001b[0;32m    420\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(path, pathlib\u001b[38;5;241m.\u001b[39mPath):\n\u001b[0;32m    421\u001b[0m         path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(path\u001b[38;5;241m.\u001b[39mresolve())\n\u001b[1;32m--> 422\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m    423\u001b[0m         img \u001b[38;5;241m=\u001b[39m pil_image\u001b[38;5;241m.\u001b[39mopen(io\u001b[38;5;241m.\u001b[39mBytesIO(f\u001b[38;5;241m.\u001b[39mread()))\n\u001b[0;32m    424\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'D:\\\\IBM\\\\Asssignment\\\\Flowers-Dataset\\\\flowers\\\\daisy.jpeg'"
     ]
    }
   ],
   "source": [
    "img=image.load_img(r\"D:\\IBM\\Asssignment\\Flowers-Dataset\\flowers\\daisy.jpeg\",target_size=(64,64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aba88a3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6fa8fbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "x=image.img_to_array(img)\n",
    "x=np.expand_dims(x,axis=0)\n",
    "y=np.argmax(model.predict(x),axis=1)\n",
    "# x_train.class_indices\n",
    "index=['daisy','dandelion','rose','sunflower','tulip']\n",
    "index[y[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0b8d740",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "454eaa66",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d165f4fe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14f4bf79",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e10e79ad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db0dfb8b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb79d389",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b559c9e6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
